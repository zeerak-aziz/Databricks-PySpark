{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8b524b8-6142-4357-8d40-1ebeb725e6ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import msal\n",
    "import json\n",
    "import logging\n",
    "import requests\n",
    "import os\n",
    "import base64\n",
    "from datetime import datetime, timedelta\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.application import MIMEApplication\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.dbutils import DBUtils  # For secret management in Databricks\n",
    "\n",
    "# Initialize Databricks Utilities\n",
    "dbutils = DBUtils(spark)\n",
    "\n",
    "# Microsoft 365 Application credentials fetched from Databricks secrets\n",
    "CLIENT_ID = dbutils.secrets.get(scope=\"project-hercules\", key=\"CLIENT_ID\")\n",
    "CLIENT_SECRET = dbutils.secrets.get(scope=\"project-hercules\", key=\"CLIENT_SECRET\")\n",
    "TENANT_ID = dbutils.secrets.get(scope=\"project-hercules\", key=\"TENANT_ID\")\n",
    "MAIL_USERNAME = 'hercules@kubrickgroup.com'\n",
    "\n",
    "AUTHORITY = f\"https://login.microsoftonline.com/{TENANT_ID}\"\n",
    "SCOPE = [\"https://graph.microsoft.com/.default\"]\n",
    "\n",
    "# Configure root logger\n",
    "logger = logging.getLogger(\"databricks_logger\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Add a console handler to see logs in the notebook\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler()\n",
    "    handler.setLevel(logging.DEBUG)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "logger.propagate = False  # Prevent duplicate log messages\n",
    "\n",
    "# Add handler\n",
    "if not logger.handlers:\n",
    "    logger.addHandler(ch)\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"ProjectHercules\").enableHiveSupport().getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5901f443-8732-4c7b-a0f4-e154499691da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the lists of companies and excluded people from text files\n",
    "def read_list_from_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return [line.strip() for line in file.readlines() if line.strip()]\n",
    "\n",
    "# Load company and recipient lists\n",
    "allowed_companies = read_list_from_file('list_trading_companies.txt')\n",
    "# insurance_companies = read_list_from_file('list_insurance_companies.txt')\n",
    "target_companies = read_list_from_file('list_target_companies.txt')\n",
    "\n",
    "# print(target_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aae011bb-3e96-4226-b578-ebe57903cb48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jemmasmith@kubrickgroup.com ['harrywates@kubrickgroup.com']\nbenhayes@kubrickgroup.com ['keishachristiemorgan@kubrickgroup.com', 'julialaming@kubrickgroup.com', 'riyapatel@kubrickgroup.com', 'heatherdonaldson@kubrickgroup.com', 'tobyenstone@kubrickgroup.com', 'mariahutcheson@kubrickgroup.com']\nnickallen@kubrickgroup.com ['benhunt@kubrickgroup.com', 'joannabottinojones@kubrickgroup.com', 'matttaylor@kubrickgroup.com', 'jacksanders@kubrickgroup.com', 'simonhecker@kubrickgroup.com', 'lewisbarnes@kubrickgroup.com', 'roxannegreene@kubricsweakgroup.com']\n"
     ]
    }
   ],
   "source": [
    "# Define the managers and their employees in a dictionary\n",
    "managers_employees = {\n",
    "    'jemmasmith@kubrickgroup.com': ['harrywates@kubrickgroup.com'],\n",
    "    \n",
    "    'benhayes@kubrickgroup.com': ['keishachristiemorgan@kubrickgroup.com','julialaming@kubrickgroup.com','riyapatel@kubrickgroup.com', 'heatherdonaldson@kubrickgroup.com', 'tobyenstone@kubrickgroup.com','mariahutcheson@kubrickgroup.com'],\n",
    "    \n",
    "    'nickallen@kubrickgroup.com': [ 'benhunt@kubrickgroup.com', 'joannabottinojones@kubrickgroup.com', 'matttaylor@kubrickgroup.com', 'jacksanders@kubrickgroup.com','simonhecker@kubrickgroup.com','lewisbarnes@kubrickgroup.com', 'roxannegreene@kubricsweakgroup.com'],\n",
    "}\n",
    "\n",
    "for keys,vals in managers_employees.items():\n",
    "    print(keys,vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e54d5eb-cfbf-4951-86de-36d46cfddbf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_company_postings(email, start_date, end_date, company_type='target'):\n",
    "    \"\"\"\n",
    "    Creates job postings DataFrame for either target companies or active trading companies\n",
    "    Parameters:\n",
    "        email (str): The email address of the user.\n",
    "        start_date (str): The start date for the job postings.\n",
    "        end_date (str): The end date for the job postings.\n",
    "        company_type (str): The type of companies to filter ('target' or 'active_trading').\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing job postings.\n",
    "    \"\"\"\n",
    "     # Determine the companies based on company_type\n",
    "    if company_type == 'target':\n",
    "        companies_str = \"', '\".join([company.replace(\"'\", \"''\") for company in target_companies])\n",
    "    elif company_type == 'active_trading':\n",
    "        companies_str = \"', '\".join([company.replace(\"'\", \"''\") for company in allowed_companies])\n",
    "    else:\n",
    "        raise ValueError(\"Invalid company_type. Must be 'target' or 'active_trading'.\")\n",
    "\n",
    "    # Query to fetch job postings\n",
    "    query = f\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            j.companyName AS Company,\n",
    "            j.jobTitle AS Title,\n",
    "            j.jobFunctions AS JobFunction,\n",
    "            j.country AS Country,\n",
    "            j.city AS City,\n",
    "            j.seniority AS Seniority,\n",
    "            j.linkedinJobPostUrl AS URL,\n",
    "            j.skill AS Skill\n",
    "        FROM hive_metastore.goldlayer_coresignal.recent_jobs_with_industries AS j\n",
    "        JOIN hive_metastore.goldlayer_coresignal.salesforce_rivery_gold AS c\n",
    "            ON LOWER(j.companyName) = LOWER(c.company_name)\n",
    "        WHERE c.Email = '{email}'\n",
    "          AND j.jobPostedDate BETWEEN '{start_date}' AND '{end_date}'\n",
    "          AND j.country = 'United Kingdom'\n",
    "          AND j.companyName IN ('{companies_str}')\n",
    "    \"\"\"\n",
    "    \n",
    "    result = spark.sql(query)  # Replace this with your actual Spark SQL execution\n",
    "    df = result.toPandas()\n",
    "\n",
    "    if df.empty:\n",
    "        logger.info(f\"No {company_type} job postings found for email: {email}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if no postings found\n",
    "    else:\n",
    "        logger.info(f\"{company_type} job postings found for email: {email}\")\n",
    "\n",
    "    # Making URLs clickable\n",
    "    df['URL'] = df['URL'].apply(lambda url: f'<a href=\"{url}\">{url}</a>')\n",
    "    df['Location'] = df['City'] + ', ' + df['Country']\n",
    "\n",
    "    # Fill missing columns\n",
    "    required_columns = ['Company', 'Title', 'JobFunction', 'Location', 'Seniority', 'URL', 'Skill', 'Country']\n",
    "    for column in required_columns:\n",
    "        if column not in df.columns:\n",
    "            df[column] = ''\n",
    "        df[column] = df[column].fillna('').astype(str)\n",
    "\n",
    "    # ** Grouping by unique job postings and aggregating skills **\n",
    "    df = df.groupby(['Company', 'Title', 'JobFunction', 'Location', 'Seniority', 'URL', 'Country'], as_index=False).agg({\n",
    "        'Skill': lambda x: ', '.join(sorted(set(x)))  # Aggregate and join skills\n",
    "    })\n",
    "\n",
    "    # Sort by 'JobPostingsCount' in descending order and then by 'Company'\n",
    "    df = df.sort_values(by=['Company'], ascending=[True]).reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# create_company_postings('harrywates@kubrickgroup.com', '2024-11-10', '2024-11-24', 'active_trading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3808395-4842-4396-96ee-88f38678e781",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def collate_job_postings(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Collate job postings for all managers and their employees into separate DataFrames.\n",
    "    Parameters:\n",
    "        start_date (str): The start date for the job postings.\n",
    "        end_date (str): The end date for the job postings.\n",
    "    Returns:\n",
    "        dict: A dictionary with managers' emails as keys and DataFrames as values.\n",
    "    \"\"\"\n",
    "    managers_postings = {}\n",
    "\n",
    "    for manager_email, employees in managers_employees.items():\n",
    "        all_postings = []\n",
    "\n",
    "\n",
    "        # Collate target company postings\n",
    "        for employee_email in employees:\n",
    "            target_postings = create_company_postings(employee_email, start_date, end_date, company_type='target')\n",
    "            active_trading_postings = create_company_postings(employee_email, start_date, end_date, company_type='active_trading')\n",
    "\n",
    "            if not target_postings.empty:\n",
    "                all_postings.append((employee_email, 'target', target_postings))\n",
    "            if not active_trading_postings.empty:\n",
    "                all_postings.append((employee_email, 'active_trading', active_trading_postings))\n",
    "\n",
    "       # Create a summary DataFrame for the manager\n",
    "        manager_summary = {\n",
    "            'active_trading': pd.concat([postings for _, type_, postings in all_postings if type_ == 'active_trading'], ignore_index=True) if any(type_ == 'active_trading' for _, type_, _ in all_postings) else pd.DataFrame(),\n",
    "            'target': pd.concat([postings for _, type_, postings in all_postings if type_ == 'target'], ignore_index=True) if any(type_ == 'target' for _, type_, _ in all_postings) else pd.DataFrame(),\n",
    "        }\n",
    "\n",
    "       # Sort and group the postings by company name\n",
    "        for key in manager_summary.keys():\n",
    "            if not manager_summary[key].empty:\n",
    "                # Group by company and count postings\n",
    "                company_counts = (\n",
    "                    manager_summary[key]\n",
    "                    .groupby('Company', as_index=False)\n",
    "                    .agg(PostingsCount=('Title', 'count'))  # Count the number of postings\n",
    "                )\n",
    "                \n",
    "                # Merge counts back to the original postings\n",
    "                manager_summary[key] = (\n",
    "                    manager_summary[key]\n",
    "                    .merge(company_counts, on='Company', how='left')\n",
    "                    .sort_values(by=['PostingsCount','Company'], ascending=[False,True])  # Sort by company name\n",
    "                    .reset_index(drop=True)  # Reset index\n",
    "                )\n",
    "\n",
    "\n",
    "       # Ensure both target and active_trading keys exist, even if empty\n",
    "        if 'target' not in manager_summary:\n",
    "            manager_summary['target'] = pd.DataFrame()\n",
    "        if 'active_trading' not in manager_summary:\n",
    "            manager_summary['active_trading'] = pd.DataFrame()\n",
    "\n",
    "        if all_postings:\n",
    "            logger.info(f\"Total postings collected for {manager_email}: {len(all_postings)}\")\n",
    "\n",
    "         # Logging the manager's summary shape\n",
    "        logger.info(f\"Manager {manager_email} summary - Target: {manager_summary['target'].shape[0]} rows, Active Trading: {manager_summary['active_trading'].shape[0]} rows\")\n",
    "\n",
    "        managers_postings[manager_email] = manager_summary\n",
    "\n",
    "    return managers_postings\n",
    "\n",
    "# Example usage\n",
    "# managers_postings = collate_job_postings('2024-11-10', '2024-11-24')\n",
    "\n",
    "# Output the results for each manager\n",
    "# for manager_email, postings in managers_postings.items():\n",
    "#     print(f\"\\nManager: {manager_email}\")\n",
    "#     print(\"Target Companies DataFrame:\")\n",
    "#     display(postings[\"target\"])\n",
    "#     print(\"\\nActive Trading Companies DataFrame:\")\n",
    "#     display(postings[\"active_trading\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "157ed386-7d14-4919-ab29-04f237527d32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 16:19:22,566 - databricks_logger - INFO - Querying job postings between 2024-11-18 and 2024-11-24\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.application import MIMEApplication\n",
    "import smtplib\n",
    "import pandas as pd\n",
    "\n",
    "# Calculate the date range for the previous week\n",
    "today = datetime.today()\n",
    "last_monday = today - timedelta(days=today.weekday() + 7)\n",
    "last_sunday = last_monday + timedelta(days=6)\n",
    "start_date = last_monday.strftime('%Y-%m-%d')\n",
    "end_date = last_sunday.strftime('%Y-%m-%d')\n",
    "\n",
    "# Format the dates for the email\n",
    "formatted_start_date = datetime.strptime(start_date, '%Y-%m-%d').strftime('%d %B %Y')\n",
    "formatted_end_date = datetime.strptime(end_date, '%Y-%m-%d').strftime('%d %B %Y')\n",
    "\n",
    "logger.info(f\"Querying job postings between {start_date} and {end_date}\")\n",
    "\n",
    "\n",
    "# -------------------------------------------#\n",
    "def df_to_html(df, title):\n",
    "    \"\"\"Convert a DataFrame to an HTML table grouped by Company and Country, with spacing between job postings.\"\"\"\n",
    "    if df.empty:\n",
    "        return f\"<h3>{title}</h3><p>No postings found.</p>\"\n",
    "\n",
    "    # Sort the DataFrame by Company name\n",
    "    df = df.sort_values(by=['Company'], ascending=True)\n",
    "    \n",
    "    data = f\"<h3>{title}</h3>\"\n",
    "    current_company = None\n",
    "    current_country = None\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        # Group by Company and Country\n",
    "        if current_company != row['Company']:\n",
    "            if current_company is not None:\n",
    "                data += '<br><br>'  # Add space between different companies\n",
    "            data += f\"<b>{row['Company']} ({row['Country']})</b><br>\"  # Bold the company and add country in parentheses\n",
    "            current_company = row['Company']\n",
    "            current_country = row['Country']  # Initialize current_country for the new company\n",
    "\n",
    "        # Add Job Details (Title, JobFunction, Location, Seniority, URL, Skills)\n",
    "        data += (f\"{row['Title']} - {row['JobFunction']}; {row['Location']}, {row['Country']}; \"\n",
    "                 f\"{row['Seniority']}; {row['URL']}; skills - {row['Skill']}<br><br>\")  # Add space between jobs\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f5718d3-72e7-4c71-8461-dfb76724b5ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_email_body(manager_email, postings):\n",
    "    \"\"\"Create HTML email bodies for the manager's job postings.\"\"\"\n",
    "\n",
    "     # Query for team member's first name based on their email\n",
    "    name_query = f\"\"\"\n",
    "        SELECT DISTINCT First_Name\n",
    "        FROM hive_metastore.goldlayer_coresignal.salesforce_rivery_gold\n",
    "        WHERE Email = '{manager_email}'\n",
    "    \"\"\"\n",
    "    result = spark.sql(name_query).collect()\n",
    "\n",
    "    # Safely extract the first name\n",
    "    if result:\n",
    "        first_name = result[0].First_Name\n",
    "    else:\n",
    "        first_name = 'there'\n",
    "\n",
    "    email_body = f\"<p>Hi {first_name} ({manager_email}),</p>\"\n",
    "    email_body += f\"<p>Please find below the job postings for your team from {formatted_start_date} to {formatted_end_date}:</p>\"\n",
    "\n",
    "    # Target Companies\n",
    "    try:\n",
    "        target_html = df_to_html(postings['target'], \"Target Company Job Postings\")\n",
    "        email_body += target_html\n",
    "    except:\n",
    "        None\n",
    "\n",
    "    # Active & Trading Companies\n",
    "    try:\n",
    "        active_trading_html = df_to_html(postings['active_trading'], \"Active & Trading Company Job Postings\")\n",
    "        email_body += active_trading_html\n",
    "    except:\n",
    "        None\n",
    "\n",
    "    email_body += \"<p>Best Regards,<br>The Hercules Team </p>\"\n",
    "    return email_body\n",
    "\n",
    "# output= create_email_body('nickallen@kubrickgroup.com@kubrickgroup.com', postings)\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31375f76-e2dc-49c5-ba71-9c8b5e8d4537",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_access_token():\n",
    "    \"\"\"Get the access token using MSAL.\"\"\"\n",
    "    app = msal.ConfidentialClientApplication(\n",
    "        CLIENT_ID,\n",
    "        authority=AUTHORITY,\n",
    "        client_credential=CLIENT_SECRET,\n",
    "    )\n",
    "    result = app.acquire_token_for_client(scopes=SCOPE)\n",
    "    if \"access_token\" in result:\n",
    "        return result['access_token']\n",
    "    raise Exception(\"Failed to acquire token\", result.get(\"error\"), result.get(\"error_description\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82dc3192-b506-4aba-af1b-fd2022f67e0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def send_email_via_graph_api(subject, recipient, body, attachment=None, attachment_name=None):\n",
    "    recipient='jackseery@kubrickgroup.com'\n",
    "    access_token = get_access_token()\n",
    "    headers = {'Authorization': f'Bearer {access_token}', 'Content-Type': 'application/json'}\n",
    "\n",
    "    email_data = {\n",
    "        \"message\": {\n",
    "            \"subject\": subject,\n",
    "            \"body\": {\"contentType\": \"HTML\", \"content\": body},\n",
    "            \"from\": {\"emailAddress\": {\"address\": MAIL_USERNAME}},\n",
    "            \"toRecipients\": [{\"emailAddress\": {\"address\": recipient}}],\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if attachment:\n",
    "        email_data[\"message\"][\"attachments\"] = [\n",
    "            {\"@odata.type\": \"#microsoft.graph.fileAttachment\", \"name\": attachment_name, \"contentBytes\": base64.b64encode(attachment).decode('utf-8')}\n",
    "        ]\n",
    "\n",
    "    response = requests.post(f'https://graph.microsoft.com/v1.0/users/{MAIL_USERNAME}/sendMail', headers=headers, data=json.dumps(email_data))\n",
    "    if response.status_code != 202:\n",
    "        raise Exception(f\"Error sending email: {response.status_code} - {response.text}\")\n",
    "    logger.info(f\"Email sent to {recipient}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebefadc5-d681-4328-b8b0-d4b7a641b377",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 16:19:23,505 - databricks_logger - INFO - target job postings found for email: harrywates@kubrickgroup.com\n2024-11-29 16:19:24,043 - databricks_logger - INFO - active_trading job postings found for email: harrywates@kubrickgroup.com\n2024-11-29 16:19:24,068 - databricks_logger - INFO - Total postings collected for jemmasmith@kubrickgroup.com: 2\n2024-11-29 16:19:24,068 - databricks_logger - INFO - Manager jemmasmith@kubrickgroup.com summary - Target: 6 rows, Active Trading: 36 rows\n2024-11-29 16:19:24,556 - databricks_logger - INFO - target job postings found for email: keishachristiemorgan@kubrickgroup.com\n2024-11-29 16:19:25,069 - databricks_logger - INFO - active_trading job postings found for email: keishachristiemorgan@kubrickgroup.com\n2024-11-29 16:19:25,532 - databricks_logger - INFO - No target job postings found for email: julialaming@kubrickgroup.com\n2024-11-29 16:19:26,037 - databricks_logger - INFO - active_trading job postings found for email: julialaming@kubrickgroup.com\n2024-11-29 16:19:26,540 - databricks_logger - INFO - target job postings found for email: riyapatel@kubrickgroup.com\n2024-11-29 16:19:27,030 - databricks_logger - INFO - active_trading job postings found for email: riyapatel@kubrickgroup.com\n2024-11-29 16:19:27,541 - databricks_logger - INFO - target job postings found for email: heatherdonaldson@kubrickgroup.com\n2024-11-29 16:19:28,029 - databricks_logger - INFO - active_trading job postings found for email: heatherdonaldson@kubrickgroup.com\n2024-11-29 16:19:28,536 - databricks_logger - INFO - target job postings found for email: tobyenstone@kubrickgroup.com\n2024-11-29 16:19:29,026 - databricks_logger - INFO - active_trading job postings found for email: tobyenstone@kubrickgroup.com\n2024-11-29 16:19:29,346 - databricks_logger - INFO - No target job postings found for email: mariahutcheson@kubrickgroup.com\n2024-11-29 16:19:29,658 - databricks_logger - INFO - No active_trading job postings found for email: mariahutcheson@kubrickgroup.com\n2024-11-29 16:19:29,672 - databricks_logger - INFO - Total postings collected for benhayes@kubrickgroup.com: 9\n2024-11-29 16:19:29,673 - databricks_logger - INFO - Manager benhayes@kubrickgroup.com summary - Target: 29 rows, Active Trading: 113 rows\n2024-11-29 16:19:30,194 - databricks_logger - INFO - target job postings found for email: benhunt@kubrickgroup.com\n2024-11-29 16:19:30,723 - databricks_logger - INFO - active_trading job postings found for email: benhunt@kubrickgroup.com\n2024-11-29 16:19:31,066 - databricks_logger - INFO - No target job postings found for email: joannabottinojones@kubrickgroup.com\n2024-11-29 16:19:31,373 - databricks_logger - INFO - No active_trading job postings found for email: joannabottinojones@kubrickgroup.com\n2024-11-29 16:19:31,828 - databricks_logger - INFO - No target job postings found for email: matttaylor@kubrickgroup.com\n2024-11-29 16:19:32,328 - databricks_logger - INFO - active_trading job postings found for email: matttaylor@kubrickgroup.com\n2024-11-29 16:19:32,848 - databricks_logger - INFO - target job postings found for email: jacksanders@kubrickgroup.com\n2024-11-29 16:19:33,357 - databricks_logger - INFO - active_trading job postings found for email: jacksanders@kubrickgroup.com\n2024-11-29 16:19:33,858 - databricks_logger - INFO - target job postings found for email: simonhecker@kubrickgroup.com\n2024-11-29 16:19:34,394 - databricks_logger - INFO - active_trading job postings found for email: simonhecker@kubrickgroup.com\n2024-11-29 16:19:34,917 - databricks_logger - INFO - target job postings found for email: lewisbarnes@kubrickgroup.com\n2024-11-29 16:19:35,423 - databricks_logger - INFO - active_trading job postings found for email: lewisbarnes@kubrickgroup.com\n2024-11-29 16:19:35,729 - databricks_logger - INFO - No target job postings found for email: roxannegreene@kubricsweakgroup.com\n2024-11-29 16:19:36,030 - databricks_logger - INFO - No active_trading job postings found for email: roxannegreene@kubricsweakgroup.com\n2024-11-29 16:19:36,045 - databricks_logger - INFO - Total postings collected for nickallen@kubrickgroup.com: 9\n2024-11-29 16:19:36,046 - databricks_logger - INFO - Manager nickallen@kubrickgroup.com summary - Target: 298 rows, Active Trading: 162 rows\n2024-11-29 16:19:36,047 - databricks_logger - INFO - Postings for jemmasmith@kubrickgroup.com: dict_keys(['active_trading', 'target'])\n2024-11-29 16:19:37,046 - databricks_logger - INFO - Email sent to jackseery@kubrickgroup.com\n2024-11-29 16:19:37,879 - databricks_logger - INFO - Email sent to jackseery@kubrickgroup.com\n2024-11-29 16:19:37,880 - databricks_logger - INFO - Postings for benhayes@kubrickgroup.com: dict_keys(['active_trading', 'target'])\n2024-11-29 16:19:38,696 - databricks_logger - INFO - Email sent to jackseery@kubrickgroup.com\n2024-11-29 16:19:39,517 - databricks_logger - INFO - Email sent to jackseery@kubrickgroup.com\n2024-11-29 16:19:39,519 - databricks_logger - INFO - Postings for nickallen@kubrickgroup.com: dict_keys(['active_trading', 'target'])\n2024-11-29 16:19:40,347 - databricks_logger - INFO - Email sent to jackseery@kubrickgroup.com\n2024-11-29 16:19:41,144 - databricks_logger - INFO - Email sent to jackseery@kubrickgroup.com\n"
     ]
    }
   ],
   "source": [
    "def send_manager_emails(managers_postings):\n",
    "    \"\"\"Send emails to each manager with their respective job postings.\"\"\"\n",
    "    for manager_email, postings in managers_postings.items():\n",
    "        logger.info(f\"Postings for {manager_email}: {postings.keys()}\")  # Log available keys\n",
    "        \n",
    "        # Check if 'target' and 'active_trading' exist\n",
    "        if 'target' in postings:\n",
    "            subject_target = \"Target Company Job Postings\"\n",
    "            body_target = create_email_body(manager_email,{\n",
    "                'target': postings['target']\n",
    "            })\n",
    "            send_email_via_graph_api(subject_target, manager_email, body_target)\n",
    "        else:\n",
    "            logger.warning(f\"No target postings for {manager_email}\")\n",
    "\n",
    "        if 'active_trading' in postings:\n",
    "            subject_trading = \"Active & Trading Company Job Postings\"\n",
    "            body_trading = create_email_body(manager_email, {\n",
    "                'active_trading': postings['active_trading']\n",
    "            })\n",
    "            send_email_via_graph_api(subject_trading, manager_email, body_trading)\n",
    "        else:\n",
    "            logger.warning(f\"No active trading postings for {manager_email}\")\n",
    "\n",
    "# Main execution\n",
    "managers_postings = collate_job_postings(start_date, end_date)\n",
    "\n",
    "# Replace with your actual email and password\n",
    "send_manager_emails(managers_postings)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Email_Automation_Sales_Leaders_New",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
