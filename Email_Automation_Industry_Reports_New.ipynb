{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7b9e420-8253-42a3-9d1b-9deb0c0c2ee8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This code aims to automate the delivery of job postings at the industry level to all members of the client team. The objective is to ensure that each member receives timely and relevant job postings within their respective industries, thereby improving the efficiency of job leads and enhancing the value provided to our clients.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84a7a268-4fec-463f-9b05-334a3eec6361",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import msal\n",
    "import json\n",
    "import logging\n",
    "import requests\n",
    "import os\n",
    "import base64\n",
    "from datetime import datetime, timedelta\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.application import MIMEApplication\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.dbutils import DBUtils  # For secret management in Databricks\n",
    "\n",
    "# Initialize Databricks Utilities\n",
    "dbutils = DBUtils(spark)\n",
    "\n",
    "# Microsoft 365 Application credentials fetched from Databricks secrets\n",
    "CLIENT_ID = dbutils.secrets.get(scope=\"n/a\", key=\"CLIENT_ID\")\n",
    "CLIENT_SECRET = dbutils.secrets.get(scope=\"n/a\", key=\"CLIENT_SECRET\")\n",
    "TENANT_ID = dbutils.secrets.get(scope=\"n/a\", key=\"TENANT_ID\")\n",
    "MAIL_USERNAME = 'n/a'\n",
    "\n",
    "AUTHORITY = f\"https://login.microsoftonline.com/{TENANT_ID}\"\n",
    "SCOPE = [\"https://graph.microsoft.com/.default\"]\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"n/a\").enableHiveSupport().getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddce857d-d282-477a-81d6-83285836de93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read the lists of companies and excluded people from text files\n",
    "def read_list_from_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return [line.strip() for line in file.readlines() if line.strip()]\n",
    "\n",
    "# Load company and recipient lists\n",
    "target_companies = read_list_from_file('list_target_companies.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1c9e817-6626-4ea3-9a85-9ee070cb4751",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_access_token():\n",
    "    \"\"\"Get the access token using MSAL.\"\"\"\n",
    "    app = msal.ConfidentialClientApplication(\n",
    "        CLIENT_ID,\n",
    "        authority=AUTHORITY,\n",
    "        client_credential=CLIENT_SECRET,\n",
    "    )\n",
    "    result = app.acquire_token_for_client(scopes=SCOPE)\n",
    "    if \"access_token\" in result:\n",
    "        return result['access_token']\n",
    "    raise Exception(\"Failed to acquire token\", result.get(\"error\"), result.get(\"error_description\"))\n",
    "\n",
    "def make_clickable(url):\n",
    "  return f'<a href=\"{url}\">{url}</a>'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db2526fb-6611-401e-a841-b883b53b24ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def send_email_via_graph_api(subject, recipient, body, attachment=None, attachment_name=None):\n",
    "    recipient='n/a'\n",
    "    access_token = get_access_token()\n",
    "    headers = {'Authorization': f'Bearer {access_token}', 'Content-Type': 'application/json'}\n",
    "\n",
    "    email_data = {\n",
    "        \"message\": {\n",
    "            \"subject\": subject,\n",
    "            \"body\": {\"contentType\": \"HTML\", \"content\": body},\n",
    "            \"from\": {\"emailAddress\": {\"address\": MAIL_USERNAME}},\n",
    "            \"toRecipients\": [{\"emailAddress\": {\"address\": recipient}}],\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if attachment:\n",
    "        email_data[\"message\"][\"attachments\"] = [\n",
    "            {\"@odata.type\": \"#microsoft.graph.fileAttachment\", \"name\": attachment_name, \"contentBytes\": base64.b64encode(attachment).decode('utf-8')}\n",
    "        ]\n",
    "\n",
    "    response = requests.post(f'https://graph.microsoft.com/v1.0/users/{MAIL_USERNAME}/sendMail', headers=headers, data=json.dumps(email_data))\n",
    "    if response.status_code != 202:\n",
    "        raise Exception(f\"Error sending email: {response.status_code} - {response.text}\")\n",
    "    logger.info(f\"Email sent to {recipient}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1836ab72-70a1-49ce-a9a6-b4d7876bb1d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_and_send_emails(start_date, end_date):\n",
    "    # Get distinct team members and industries from the data\n",
    "    industries_query = \"\"\"\n",
    "        SELECT DISTINCT team_member, company_industry\n",
    "        FROM hive_metastore.goldlayer_coresignal.industries_primary_recent\n",
    "    \"\"\"\n",
    "    industries_df = spark.sql(industries_query).toPandas()\n",
    "\n",
    "    for _, industry_row in industries_df.iterrows():\n",
    "        team_member = industry_row['team_member']\n",
    "        company_industry = industry_row['company_industry']\n",
    "\n",
    "        # Query job postings for each team member's industry\n",
    "        jobs_query = f\"\"\"\n",
    "            SELECT DISTINCT\n",
    "                companyName,\n",
    "                jobTitle,\n",
    "                jobFunction,\n",
    "                jobPostedDate,\n",
    "                skill,\n",
    "                city,\n",
    "                country,\n",
    "                seniority,\n",
    "                postURL\n",
    "            FROM hive_metastore.goldlayer_coresignal.industries_primary_recent\n",
    "            WHERE team_member = '{team_member}'\n",
    "              AND company_industry = '{company_industry}'\n",
    "              AND country = 'United Kingdom'\n",
    "              AND jobPostedDate BETWEEN '{start_date}' AND '{end_date}'\n",
    "        \"\"\"\n",
    "        job_posts_df = spark.sql(jobs_query).toPandas()\n",
    "\n",
    "        if job_posts_df.empty:\n",
    "            logger.info(f\"No job postings found for {team_member} in {company_industry} industry.\")\n",
    "            continue\n",
    "\n",
    "        # Convert postURL to clickable format\n",
    "        job_posts_df['postURL'] = job_posts_df['postURL'].apply(make_clickable)\n",
    "        job_posts_df['Location'] = job_posts_df['city'] + ', ' + job_posts_df['country']\n",
    "\n",
    "        # Convert jobFunction array to a string for grouping\n",
    "        job_posts_df['jobFunction'] = job_posts_df['jobFunction'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "        # Aggregate skills and format each job posting, ignoring None values in the skill column\n",
    "        job_posts_df = job_posts_df.groupby(\n",
    "            ['companyName', 'jobTitle', 'jobFunction', 'jobPostedDate', 'Location', 'seniority', 'postURL', 'country'], as_index=False\n",
    "        ).agg({'skill': lambda x: ', '.join(sorted(set([s for s in x if s is not None])))})\n",
    "\n",
    "        # Generate email body content\n",
    "        job_postings_content = ''\n",
    "        current_company = None\n",
    "        for _, row in job_posts_df.iterrows():\n",
    "            if current_company != row['companyName']:\n",
    "                if current_company is not None:\n",
    "                    job_postings_content += '<br>'\n",
    "                job_postings_content += f\"<b>{row['companyName']}</b> ({row['country']})<br><br>\"\n",
    "                current_company = row['companyName']\n",
    "            job_postings_content += f\"{row['jobTitle']}; {row['jobFunction']}; {row['Location']}; {row['seniority']}; {row['postURL']}; skills - {row['skill']}<br><br>\"\n",
    "\n",
    "        formatted_start_date = datetime.strptime(start_date, '%Y-%m-%d').strftime('%d %B %Y')\n",
    "        formatted_end_date = datetime.strptime(end_date, '%Y-%m-%d').strftime('%d %B %Y')\n",
    "\n",
    "        # Prepare email\n",
    "        email_body = f\"\"\"\n",
    "            <html>\n",
    "            <body>\n",
    "            <p>Good morning {team_member},<br><br>\n",
    "            Here are the job postings for the <b>{company_industry}</b> industry between {formatted_start_date} and {formatted_end_date}:</p>\n",
    "            <p>{job_postings_content}</p>\n",
    "            </body>\n",
    "            </html>\n",
    "        \"\"\"\n",
    "        subject = f\"{company_industry} Industry â€“ Weekly Job Postings Report\"\n",
    "\n",
    "        # Send email\n",
    "        send_email_via_graph_api(team_member, subject, email_body)\n",
    "\n",
    "# Define date range for the previous week\n",
    "today = datetime.today()\n",
    "last_monday = today - timedelta(days=today.weekday() + 7)\n",
    "last_sunday = last_monday + timedelta(days=6)\n",
    "start_date = last_monday.strftime('%Y-%m-%d')\n",
    "end_date = last_sunday.strftime('%Y-%m-%d')\n",
    "\n",
    "# Run the email creation and sending process\n",
    "create_and_send_emails(start_date, end_date)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Email_Automation_Industry_Reports_New",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
